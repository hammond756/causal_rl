{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "from operator import lt, gt, eq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(directory):\n",
    "    stats = []\n",
    "    for timestamp in os.listdir(directory):\n",
    "        file_path = '/'.join([directory, str(timestamp), 'stats.pkl'])\n",
    "        with open(file_path, 'rb') as f:\n",
    "            stats.append(pickle.load(f))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def model_is_correct(w_true, w_model, threshold=0.1):\n",
    "    return num_edges_correct(w_true, w_model, threshold) == legal_edges(len(w_true))\n",
    "\n",
    "def num_edges_correct(w_true, w_model, threshold=0.1):\n",
    "    # correct for 'illegal' edges because those are not learned and are always zero\n",
    "    return ((w_model - w_true).abs().view(-1) < threshold).sum().item() - illegal_edges(len(w_true))\n",
    "\n",
    "def total_edges(dim):\n",
    "    return dim**2\n",
    "\n",
    "def legal_edges(dim):\n",
    "    return (dim - 1)**(2) / 2\n",
    "\n",
    "def non_zero_edges(w_true):\n",
    "    return (w_true != 0).sum().item()\n",
    "\n",
    "def sparsity(w_true):\n",
    "    return non_zero_edges(w_true) / legal_edges(len(w_true))\n",
    "\n",
    "def illegal_edges(dim):\n",
    "    return total_edges(dim) - legal_edges(dim)\n",
    "\n",
    "def get_data(directory):\n",
    "    stats = get_stats(directory)\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for stat in stats:\n",
    "        \n",
    "        w_true = stat['true_weights']\n",
    "        w_model = stat['model_weights']\n",
    "        \n",
    "        for i in range(len(stat['iterations'])):\n",
    "            data = data.append({\n",
    "                'dim' : int(w_true.shape[0]),\n",
    "                'sparsity' : stat['config'].random_dag[1],\n",
    "#                 'model_correct' : model_is_correct(w_true, w_model, threshold),\n",
    "#                 'num_correct' : num_edges_correct(w_true, w_model, threshold),\n",
    "#                 'total_edges' : total_edges(dim),\n",
    "#                 'legal_edges' : legal_edges(dim),\n",
    "#                 'percent_correct' : num_edges_correct(w_true, w_model, threshold) / legal_edges(dim),\n",
    "                'model_name' : stat['config'].dag_name,\n",
    "                'causal_err' : stat['causal_err'][i],\n",
    "                'noise_err' : stat['noise_err'][i],\n",
    "                'loss' : stat['loss']['pred'][i],\n",
    "                'iterations' : stat['iterations'][i] + 1,\n",
    "                'seed' : stat['config'].seed,\n",
    "            }, ignore_index=True)\n",
    "    \n",
    "    data['dim'] = data['dim'].astype(int)\n",
    "    return data\n",
    "\n",
    "def relative_distance(A, B):\n",
    "    assert A.size() == B.size(), 'Matrices should be equal shape'\n",
    "    \n",
    "    n,m = A.size()\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if A[i,j].item() != 0:\n",
    "                result.append((A[i,j] - B[i,j]).abs() / A[i,j].abs())\n",
    "    \n",
    "    return torch.tensor(result).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_data('../experiments/faulty_noise_err_progressive_size_two_step/')\n",
    "# data = get_data('../experiments/no_noise_err_three_var_two_step//')\n",
    "# data = get_data('../experiments/2493794/')\n",
    "# data = get_data('../experiments/stacked_chain_two_step')\n",
    "data = get_data('/Volumes/Lisa/causal_rl/experiments/2494061')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, column, compare_func, value):\n",
    "    return data[compare_func(data[column], value)]\n",
    "\n",
    "data['split'] = data['sparsity'] > 0.5\n",
    "sns.relplot(x='iterations', y='noise_err', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH PAPER BEYOND THIS POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt(data['iterations'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistic_to_iterations(experiments):\n",
    "    \n",
    "    causal_errs = np.zeros((1, 50))\n",
    "    fix, ax = plt.subplots(1,1)\n",
    "    print(ax)\n",
    "    for experiment in experiments:\n",
    "\n",
    "        stats = get_stats('../{}/{}'.format('experiments', experiment))\n",
    "                        \n",
    "        causal_errs = [stat['causal_err'] for stat in stats]\n",
    "        log_iters = np.tile(stats[0]['iterations'], len(causal_errs))\n",
    "        causal_errs = np.array(causal_errs).reshape(1,-1).squeeze()\n",
    "\n",
    "        print(causal_errs.shape, log_iters.shape)\n",
    "#         sns.lineplot(x=log_iters, y=causal_errs, ax=ax)        \n",
    "\n",
    "        for stat in stats:\n",
    "            print(stat['true_weights'])\n",
    "            print(stat['model_weights'])\n",
    "            print(stat['causal_err'][-1])\n",
    "            sns.lineplot(x=np.array(stat['iterations']), y=np.array(stat['causal_err']), ax=ax)\n",
    "\n",
    "#     ax.legend(experiments)\n",
    "    ax.set_title('causal_err')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel('causal_err')\n",
    "#     plt.ylim(bottom=0, top=1)\n",
    "        \n",
    "plot_statistic_to_iterations(['large_random_net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_of_correct_models(path_to_experiment):\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    stats = get_stats(path_to_experiment)\n",
    "    \n",
    "    for i, stat in enumerate(stats):\n",
    "        w_model = stat['model_weights']\n",
    "        w_true = stat['true_weights']\n",
    "        dim = len(w_true)\n",
    "                        \n",
    "        threshold = 0.2\n",
    "        \n",
    "#         print(model_is_correct(w_true, w_model, threshold))\n",
    "#         print(w_model)\n",
    "#         print(w_true)\n",
    "#         print()\n",
    "        data = data.append({\n",
    "            'dim' : dim,\n",
    "            'model_correct' : model_is_correct(w_true, w_model, threshold),\n",
    "            'signs_correct' : signs_are_correct(w_true, w_model),\n",
    "            'zeros_correct' : zeros_correct(w_true, w_model, threshold),\n",
    "            'num_correct' : num_edges_correct(w_true, w_model, threshold),\n",
    "            'total_edges' : total_edges(dim),\n",
    "            'legal_edges' : legal_edges(dim),\n",
    "            'percent_correct' : num_edges_correct(w_true, w_model, threshold) / legal_edges(dim),\n",
    "            'model_name' : stat['config'].dag_name,\n",
    "            'causal_err' : (w_true - w_model).abs().sum().item() / legal_edges(dim),\n",
    "            'loss' : stat['loss']['pred'][-1],\n",
    "            'seed' : stat['config'].seed,\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "#     g = sns.barplot(x='dim', y='legal_edges', data=data)\n",
    "    g = sns.catplot(x='dim', y='noise_err', data=data)\n",
    "    g.set_xticklabels(rotation=30, ha='right')\n",
    "\n",
    "# plot_number_of_correct_models(os.path.join('../experiments/repeated_no_reg/'))\n",
    "plot_number_of_correct_models(os.path.join('../experiments/2493794/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_loss_to_optimal(path_to_experiment):\n",
    "    \n",
    "    stats = get_stats(path_to_experiment)    \n",
    "#     fig, axes = plt.subplots(2,3, sharey=True)\n",
    "    \n",
    "    for idx, stat in enumerate(stats):\n",
    "        data = pd.DataFrame()\n",
    "        \n",
    "        w_true = stat['true_weights']\n",
    "        w_model = stat['model_weights']\n",
    "        \n",
    "        model_correct = model_is_correct(w_true, w_model, 0.15)\n",
    "                        \n",
    "        for i in range(len(stat['iterations'])):\n",
    "            data = data.append({\n",
    "                'seed' : int(stat['config'].seed),\n",
    "                'loss' : stat['loss']['total'][i],\n",
    "                'pred' : stat['loss']['pred'][i],\n",
    "                'reg' : stat['loss']['reg'][i],\n",
    "                'iterations' : stat['iterations'][i],\n",
    "                'causal_err' : stat['causal_err'][i],\n",
    "                'model_name' : stat['config'].dag_name\n",
    "            }, ignore_index=True)\n",
    "            \n",
    "        i, j = divmod(idx, 3)\n",
    "        \n",
    "        if model_correct:\n",
    "            plot_color = 'green'\n",
    "        else:\n",
    "            plot_color = 'red'\n",
    "        \n",
    "        print('correct:', model_correct)\n",
    "        print(w_true)\n",
    "        print(w_model)\n",
    "#         print()\n",
    "        \n",
    "        plt.ylim(bottom=0, top=1)\n",
    "        \n",
    "#         axes[i,j].plot(data['iterations'], data['loss'], color=plot_color)\n",
    "#         axes[i,j].plot(data['iterations'], data['ground'])\n",
    "#         plt.plot(data['iterations'], data['pred'], color=plot_color, label='model')\n",
    "#         plt.plot(data['iterations'], data['ground_pred'], label='true')\n",
    "#         plt.plot(data['iterations'], data['causal_err'], label='causal_err', color=plot_color)\n",
    "#         plt.ylabel('MSE')\n",
    "#         plt.xlabel('iterations')\n",
    "#         plt.legend()\n",
    "        sns.lineplot(x='iterations', y='causal_err', data=data)\n",
    "        \n",
    "#         plt.figure()\n",
    "        \n",
    "plot_loss_to_optimal('../experiments/two_step_no_reg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_of_loss(path_to_experiment):\n",
    "    fix, axes = plt.subplots(2,3)\n",
    "    stats = get_stats(path_to_experiment)\n",
    "    for idx, stat in enumerate(stats):\n",
    "        i,j = divmod(idx, 3)\n",
    "        print(len(stat['loss']['pred'][10000:]))\n",
    "        total_exact = ((torch.tensor(stat['loss']['pred'][10000:]) - 0).abs() < 0.05).sum()\n",
    "        print(total_exact)\n",
    "        print(total_exact.float() / len(stat['loss']['pred'][10000:]))\n",
    "        axes[i,j].hist(stat['loss']['pred'], bins=10, range=(0,1))\n",
    "        axes[i,j].hist(stat['ground_loss']['pred'], bins=10, range=(0,1))\n",
    "\n",
    "histogram_of_loss('../experiments/identify_optimization_problem_granular/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips['dim'] = np.array([int(i*10 % 3) for i in range(len(tips))])\n",
    "sns.lineplot(x='size', y='tip', hue='dim', data=tips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
